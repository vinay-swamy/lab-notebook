# Lab Notebook

## 09-09-2021(Thursday)
Right now my main focus is (at a high level) understanding how attention and transformers work in language models. I'm doign this by:

- reading the goodfellow deeplearning textbook
- blogposts()

Next, I'm going to try and figure out how to use pytorch 

## 09-19-2021(Monday)
- have read through most of the code for gMVP. Trying to run the initial data generation scripts, but missing input files. Rest of lab has not been super reponsive 
- I did find some processed files elsewhere on the `/data` drive ( in `hz**/protein/tf` ), that I might be able to use in the mean time to get something up and running 
- debating on whether or not to talk to yufeng about the lack of communication/documentation on the project. 

## 09-19-2021(Tuesday)
- realized I have no idea how to use pytorch, and will probably be more of a bottle neck, so i think it will be  a better use of my time to focus on that.
    - right now my plan is to go through tensorflow walkthroughs, but implement them in pytorch, so I will get exposure to both.
- Also, need to devote more time to the goodfellow book, bc I'm definitely feeling a bit lost math wise 
